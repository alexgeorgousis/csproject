\chapter{Conclusion}
All current state-of-the-art ML algorithms are black boxes with respect to the solutions they produce. Making those solutions interpretable is both a scientific and ethical imperative, as it will allow us to better understand and, thus, improve them while also making them more trustworthy. This project has achieved its aim of demonstrating, albeit at a small scale, that interpretability is both achievable and useful.

The first two environments tackled in this project, cart-pole and mountain-car, were relatively easy to find solutions for whereas pendulum posed more of a challenge. In all three cases, however, the combination of GP and human intervention was successful in producing simple, interpretable, and well-performing solutions. There is, of course, a lot of work that can still be done to improve the GP algorithm and extend the program structure to improve the current solutions. In particular, the experiments performed on pendulum as part of this project indicate that a few significant additions to the program structure could produce a solution that outperforms state-of-the-art neural-network-based approaches, so contributions to this (as well as to any other) part of the project are highly encouraged\footnote{The source code for this project can be found on GitHub under the MIT License: \url{https://github.com/alexgeorgousis/gp-for-interpretable-rl}}.

In principle, this approach could prove useful in solving more complicated RL environments, a task that could not be undertaken as part of this project due to time limitations. An environment like the OpenAI bipedal walker\footnote{\url{https://github.com/openai/gym/wiki/BipedalWalker-v2}} would be a reasonable next step following the progress made in this project, due to its similarity to the environments tackled here and the challenge the large amount of environmental inputs pose. The Atari games, which have become popular in RL research (see e.g. \cite{atari} and \cite{atari2}), and the MuJoCo environments\footnote{\url{https://gym.openai.com/envs/}}, which require algorithms to learn in a 3-D space, would also be interesting applications of this approach.

Finally, since this approach managed to yield solutions without a big trade-off in performance, a more rigorous comparison with neural-network-based approaches would be worth doing. Metrics such as training time, performance robustness, and code scalability are important to be measured and compared if this or similar approaches are to be used in industry.
